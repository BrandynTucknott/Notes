\documentclass{exam}

\usepackage{amsmath,amssymb,amsfonts,amsthm,dsfont}
\usepackage{lib/extra}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{bbm}
\usepackage{pgfplots}
\usepackage{fontenc}
\usepackage{float}

\pgfplotsset{compat=1.18}
\renewcommand{\arraystretch}{1.5}
\setcounter{section}{1}

\title{Complex Analysis Chapter 1 Section 2}
\author{Brandyn Tucknott}
\date{Last Updated: 24 September 2025}

\begin{document}
\maketitle

\section{Functions on the Complex Plane}
\subsection{Continuous Functions}
Let $f$ be a function on a set $\Omega$ of complex numbers. We say that $f$ is \textbf{continuous}
at a point $z_0\in\Omega$ if for every $\eps > 0$ there exists a $\delta > 0$ such that whenever
$z\in\Omega$ and $\abs{z - z_0} < \delta$ then $\abs{f(z) - f(z_0)} < \eps$. Equivalently, we can 
say for every sequence $\cbrac{z_1, z_2, \hdots}\subset \Omega$ such that $\lim z_n = z_0$, then
$\lim f(z_n) = f(z_0)$. The function $f$ is continuous on $\Omega$ if it is continuous at every
point in $\Omega$. Sums and products of continuous functions are also continuous.

It is worth noting that the function $f$ of the complex argument $z = x + iy$ is continuous if and
only if it is continuous viewed as a function of the two real variables $x, y$.

By the triangle inequality, we see that if $f$ is continuous, then the real-valued function defined
by $z\to\abs{f(z)}$ is continuous. We say that $f$ attains a \textbf{maximum} at a point $z_0\in\Omega$
if
$$\abs{f(z)} \leq \abs{f(z_0)}\text{ for all }z\in\Omega,$$
with the inequality reversed for the definition of a \textbf{minimum}.

\begin{theorem}\label{thm:main}
    A continuous function on a compact set $\Omega$ attains a maximum and minimum on $\Omega$.
\end{theorem}


\subsection{Holomorphic Functions}
Let $\Omega\subset\C$ be open and $f$ a complex-valued function on $\Omega$. The function $f$ is
\textbf{holomorphic at the point} $z_0\in\Omega$ if
$$\lim_{h\to 0}\frac{f(z_0 + h) - f(z_0)}{h}$$
converges. Here $h\in\C$ and $h\neq 0$ with $z_0 + h\in\Omega$, so that the quotient is well-defined.
The limit of the quotient, when it exists, is denoted by $f'(z_0)$ and is called the \textbf{derivative
of} $f$ \textbf{at} $z_0$:
$$f'(z_0) = \lim_{h\to 0}\frac{f(z_0 + h) - f(z_0)}{h}.$$
Take note that $h$ is complex and can approach $0$ from any direction.

The function $f$ is \textbf{holomorphic on} $\Omega$ if it is holomorphic at every point of $\Omega$.
If $C$ is a closed subset of $\C$, we say that $f$ is \textbf{holomorphic on} $C$ if $f$ is holomorphic
in some open set containing $C$. If $f$ is holomorphic on $\C$, we say that $f$ is \textbf{entire}.

\newpage
\noqed
\begin{proposition}\label{prop:main}
    If $f$ and $g$ are holomorphic in $\Omega$, then:
    \begin{itemize}
        \item $f + g$ is holomorphic in $\Omega$ and $(f + g)' = f' + g'$.

        \item $fg$ is holomorphic in $\Omega$ and $(fg)' = f'g + fg'$.

        \item If $g(z_0) \neq 0$, then $f/g$ is holomorphic at $z_0$ and
        $$(f/g)' = \frac{gf' - fg'}{g^2}.$$
    \end{itemize}

    Moreover, if $f: \Omega\to U$ and $g: U\to\C$ are holomorphic, then the chain rule holds;
    $$(g\circ f)'(z) = g'(f(z))f'(z) \text{ for all } z\in\Omega.$$
\end{proposition}
\yesqed


\subsection*{Complex-Valued Functions as Mappings}
Recall that a fuction $F(x, y) = (u(x, y), v(x, y))$ is said to be differentiable at a point $P_0 = (x_0, y_0)$ if there exists a linear
transformation $J: \R^2\to\R^2$ such that
$$\frac{\abs{F(P_0 + H) - F(P_0) - J(H)}}{\abs{H}} \to 0 \text{ as } \abs{H}\to 0, H\in\R^2$$
Equivalently we can write
$$F(P_0 + H) - F(P_0) = J(H) + \abs{H}\Psi(H),$$
with $\abs{\Psi(H)} \to 0$ as $H \to 0$. The linear transformation $J$ is unique and is called the derivative of $F$ at $P_0$. If $F$ is
differentiable, the partial derivatives of $u$ and $v$ exist and $J$ is described with the standard basis in $\R^2$ by the Jacobian of $F$
$$J = J_F(x, y) = 
\paren{\begin{matrix}
    \frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\
    \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y}
\end{matrix}}.$$

With complex-differentiation, the derivative is a complex number $f'(z_0)$, and with the reals it is a matrix. However, there is a relation
to be found involving the partials of $u$ and $v$.

Given the following equations
\begin{equation}
    \frac{f(z_0 + h) - f(z_0)}{h}
\end{equation}
\begin{equation}
    f(z_0 + h) - f(z_0) - ah = h\psi(h)
\end{equation}
\begin{equation}
    \frac{\abs{F(P_0 + H) - F(P_0) - J(H)}}{\abs{H}} \to 0 \text{ as } \abs{H\to 0}
\end{equation}
consider the limit when $h$ is real. That is, $h = h_1 + ih_2$ with $h_2 = 0$. Then if we write $z = x + iy$, $z_0 = x_0 + iy_0$, and $f(z) = f(x, y)$,
we find that
\begin{align*}
    f'(z_0) &= \lim_{h_1\to 0} \frac{f(x + h_1, y_0) - f(x_0, y_0)}{h_1} \\
    &= \frac{\partial f}{\partial x}(z_0).
\end{align*}
Now taking $h$ to be purely imaginary with $h = ih_2$, a similar argument shows that
\begin{align*}
    f'(z_0) &= \lim_{h_2\to 0}\frac{f(x_0, y_0 + h_2) - f(x_0, y_0)}{ih_2} \\
    &= \frac{1}{i} \frac{\partial f}{\partial y}(z_0).
\end{align*}

Therefore, if $f$ is holomorphic, we have shown that 
$$\frac{\partial f}{\partial x} = \frac{1}{i}\frac{\partial f}{\partial y}.$$
Writing $f = u + iv$ after seperating real and imaginary parts as well as using $1 / i = -i$, we find that the partials of $u$ and $v$ exist,
and they satisfy the following relations:
$$\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y} \text{ and } \frac{\partial u}{\partial y} = -\frac{\partial v}{\partial x}.$$
These are the \textbf{Cauchy-Riemann equations}. We can take this further and define two differential operators:
$$\frac{\partial}{\partial z} = \frac{1}{2}\paren{\frac{\partial}{\partial x} + \frac{1}{i}\frac{\partial}{\partial y}} 
\text{ and } 
\frac{\partial}{\partial \overline{z}} = \frac{1}{2}\paren{\frac{\partial}{\partial x} - \frac{1}{i}\frac{\partial}{\partial y}}.$$

\noqed
\begin{proposition}\label{prop:main}
    If $f$ is holomorphic at $z_0$, then
    $$\frac{\partial f}{\partial \overline{z}} = 0 \text{ and } 
    f'(z_0) = \frac{\partial f}{\partial z}(z_0) = 2\frac{\partial u}{\partial z}(z_0).$$
    Also, if we write $F(x, y) = f(z)$, then $F$ is differentiable in the sense of real variables, and
    $$\det{J_F}(x_0, y_0) = \abs{f'(z_0)}^2.$$
\end{proposition}
\yesqed
\begin{proof}
    Taking real and imaginary parts, it is easy to see the Cauchy-Riemann equations are equivalent to $\partial f / \partial \overline{z} = 0$.
    By our earlier observation
    \begin{align*}
        f'(z_0) &= \frac{1}{2}\paren{\frac{\partial f}{\partial x}(z_0) + \frac{1}{i}\frac{\partial f}{\partial y}(z_0)} \\
        &= \frac{\partial f}{\partial z}(z_0)
    \end{align*}
    and the Cauchy-Riemann equations give $\partial f / \partial z = 2\partial u / \partial z$. To prove that $F$ is differentiable,
    it suffices to show that if $H = (h_1, h_2)$ and $h = h_1 + ih_2$, then the Cauchy-Riemann equations imply
    $$J_F(x_0, y_0)(H) = \paren{\frac{\partial u}{\partial x} - i\frac{\partial u}{\partial y}}(h_1 + ih_2) = f'(z_0)h,$$
    where we have identified a complex number with the pair of real and imaginary parts. Another application of the Cauchy-Riemann equations
    give
    $$\det{J_F}(x_0, y_0) = \frac{\partial u}{\partial }\frac{\partial v}{\partial y} - \frac{\partial v}{\partial x}\frac{\partial u}{\partial y}
    = \paren{\frac{\partial u}{\partial x}}^2 + \paren{\frac{\partial v}{\partial y}}^2 = \abs{2\frac{\partial u}{\partial z}}^2 = |f'(z_0)|^2.$$
\end{proof}

\noqed
\begin{theorem}\label{thm:main}
    Suppose $f = u + iv$ is a complex-valued function defined on an open set $\Omega$. If $u$ and $v$ are continuously differentiable 
    and satisfy the Cauchy-Riemann equations on $\Omega$, then $f$ is holomorphic on $\Omega$ and $f'(z) = \partial f / \partial z$.
\end{theorem}
\yesqed
\begin{proof}
    Write 
    $$u(x + h_1, y + h_2) - u(x, y) = \frac{\partial u}{\partial x}h_1 + \frac{\partial u}{\partial y}h_2 + |h|\psi_1(h)$$
    and
    $$v(x + h_1, y + h_2) - v(x, y) = \frac{\partial v}{\partial x}h_1 + \frac{\partial v}{\partial y}h_2 + |h|\psi_2(h),$$
    where $\psi_j (h)\to 0$ (for $j = 1,2$) as $|h|\to 0$ and $h = h_1 + ih_2$. Using the Cauchy-Riemann equations, we find that
    $$f(z + h) - f(z) = \paren{\frac{\partial u}{\partial x} - i\frac{\partial u}{\partial y}}(h_1 + ih_2) + |h|\psi(h),$$
    where $\psi(h) = \psi_1(h) + \psi_2(h)\to 0$ as $|h|\to 0$. Therefore $f$ is holomorphic and 
    $$f'(z) = 2\frac{\partial u}{\partial z} = \frac{\partial f}{\partial z}.$$
\end{proof}


\subsection{Power Series}
A classic example of a power series is the complex \textbf{exponential} function, defined for all $z\in\C$ by
$$e^z = \sum_{n = 0}^\infty \frac{z^n}{n!}.$$
The above series converges absolutely for all $z\in\C$, which can be seen by observing
$$\abs{\frac{z^n}{n!}} = \frac{\abs{z}^n}{n!},$$
which allows us to compare $\abs{e^z}$ with the power series $\sum_{n = 0}^\infty \abs{z}^n / n! = e^{|z|} < \infty$. Moreover, this shows
that the power series of $e^z$ converges uniformly in all discs in $\C$.

\noqed
\begin{theorem}\label{thm:main}
    Given a power series $\sum_{n = 0}^\inftya_nz^n$, there exists $0 \leq R \leq \infty$ such that:
    \begin{itemize}
        \item If $\abs{z} < R$, the series converges absolutely.
        \item If $\abs{z}  > R$, the series diverges.
    \end{itemize}
    Moreover, if we use the convention that $1 / 0 = \infty$ and $1 / \infty = 0$, then $R$ is given by Hadamard's formula
    $$\frac{1}{R} = \lim\sup \abs{a_n}^{1 / n}.$$
\end{theorem}
\yesqed

\textbf{Remark. } Notice this theorem says nothing about when $\abs{z} = R$. This situation can either converge or diverge.

The number $R$ is called the \textbf{radius of convergence} of the power series, and the region $|z| < R$ the \textbf{disc of convergence}.
Moreover, the radius of convergence for the exponential function and geometric series are $R = \infty$ and $R = 1$ respectively.

More examples of power series in the complex plane are given below in the form of \textbf{trigonometric functions}. These are defined as
$$\cos z = \sum_{n = 0}^\infty (-1)^n\frac{z^{2n}}{(2n)!} \text{ and } \sin z = \sum_{n = 0}^\infty (-1)^n\frac{z^{2n + 1}}{(2n + 1)!}.$$

A connection between these and the exponential function can be expressed as 
$$\cos z = \frac{e^{iz} + e^{-iz}}{2} \text{ and } \sin z = \frac{e^{iz} - e^{-iz}}{2i}.$$

These are called \textbf{Euler formulas} for the sine and cosine functions.

\noqed
\begin{theorem}\label{thm:main}
    The power series $f(z) = \sum_{n = 0}^\infty a_n z^n$ defines a holomorphic function in its disc of convergence. The derivative of $f$
    is also a power series obtained by differentiating the term by term power series for $f$, that is,
    $$f'(z) = \sum_{n = 1}^\infty na_n z^{n - 1}.$$
    Moreover, $f'$ has the same radius of convergence as $f$.
\end{theorem}
\yesqed

\begin{proof}
    Since $\lim_{n\to\infty} n^{1 / n} = 1$, by Hadamard's formula we know that
    $$\frac{1}{R} = \lim_{n\to\infty} \abs{n}^{1 / n} = \lim_{a_n\to\infty} \abs{na_n}^{1 / n},$$
    thus $\sum a_nz^n$ and $\sum na_nz^{n}$ have the same radius of convergence.

    To prove the first assertion, we must show that
    $$g(z) = \sum_{n = 1}^\infty na_nz^{n - 1}$$
    gives the derivative of $f$.

    Let $R$ denote the radius of convergence of $f$, and let $|z_0| < r < R$. Denote 
    $$S_N(z) = \sum_{n = 0}^N a_n z^n \text{ and } E_N(z) = \sum_{n = N + 1}^\infty a_nz^n$$
    and write
    $$f(z) = S_N(z) + E_N(z).$$

    If $h$ is chosen such that $|z_0 + h| < r$, we have
    $$\frac{f(z_0 + h) - f(z_0)}{h} - g(z_0) &= \paren{\frac{S_N(z_0 + h) - S_N(z_0)}{h} - S_N'(z_0)} + \paren{S_N'(z_0) - g(z_0)} + 
        \paren{\frac{E_N(z_0 + h) - E_N(z_0)}{h}}.$$

    Since $a^n - b^n = (a - b)(a^{n - 1} + a^{n - 2}b + \hdots + ab^{n - 2} + b^{n - 1})$, we see that
    $$\abs{\frac{E_N(z_0 + h) - E_N(z_0)}{h}} \leq \sum_{n = N + 1}^\infty |a_n|\abs{\frac{(z_0 + h)^n - z_0^n}{h}} \leq \sum_{n = N + 1}^\infty |a_n|nr^{n - 1},$$
    where we use the fact that $|z_0| < r$ and $|z_0 + h| < r$. The expression on the right is the tail end of a convergent series,
    since $g$ converges absolutely on $|z| < R$. Therefore, given $\veps > 0$, we can find $N_1$ such that $N > N_1$ implies
    $$\abs{\frac{E_N(z_0 + h) - E_N(z_0)}{h}} < \veps.$$

    Also, since $\lim_{n\to\infty} S_N'(z_0) = g(z_0)$, we can find $N_2$ such that $N > N_2$ implies
    $$\abs{S_N'(z_0) - g(z_0)} < \veps.$$

    If we fix $N$ so that $N > N_1, N_2$, we can find $\delta > 0$ so that $|h| < \delta$ implies
    $$\abs{\frac{S_N(z_0 + h) - S_N(z_0)}{h} - S_N'(z_0)} < \veps,$$
    since the derivative of a polynomrial is obtained by differentiating it term by term. Therefore

    $$\abs{\frac{f(z_0 + h) - f(z_0)}{h} - g(z_0)} < 3\veps$$
    whenever $|h| < \delta$, thereby concluding the proof of the theorem.
\end{proof}

\begin{corollary}
    A power series is infinitely complex differentiable in its disc of convergence, and the higher derivatives are also obtained by term-wise differentiation.
\end{corollary}

So far, we have only dealt with power series centered about the origin, but we more generally express a power series centered at $z_0\in\C$ as
$$f(z) = \sum_{n = 0}^\infty a_n(z - z_0)^n.$$

The disc of convergence of $f$ is now centered at $z_0$, but the radius is still given by Hadamard's formula. In fact, if
$$g(z) = \sum_{n = 0}^\infty a_n z^n,$$
$f$ is obtained by simply translating $g$.

A function $f$ defined on an open set $\Omega$ is said to be \textbf{analytic} (having a power series expansion) at a point $z_0\in\Omega$ if
there exists a power series $\sum a_n(z - z_0)^n$ centered at $z_0$ with positive radius of convergence such that
$$f(z) = \sum_{n = 0}^\infty a_n(z - z_0)^n\text{ for all $z$ in a neighborhood of $z_0$}.$$

If $f$ has a power series expansion point at every point in $\Omega$, we say that $f$ is \textbf{analytic on $\Omega$}. By Theorem 2.6, an
analytic function is also holomorphic. In the future we will prove the converse is true: every holomorphic function is analytic. For that
reason we use the terms holomorphic and analytic interchangably.

\subsection{Integration along curves}
pg 38


\end{document}